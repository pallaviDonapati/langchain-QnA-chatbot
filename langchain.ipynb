{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"] = \"your OPEN_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\llm-pro\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(openai_api_key = os.environ[\"OPEN_API_KEY\"], temperature = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\llm-pro\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of Korea is Seoul.\n"
     ]
    }
   ],
   "source": [
    "text = 'what is capital of korea'\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR_HUGGINGFACEHUB_API_TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\llm-pro\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\llm-pro\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#!pip install huggingface_hub\n",
    "\n",
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface = HuggingFaceHub(repo_id = \"google/flan-t5-large\", model_kwargs = {\"temperature\" : 0, \"max_length\" : 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Moscow'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = llm_huggingface.predict('can you tell me the capital of russia')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love you i love'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = llm_huggingface.predict('can you write a poem about AI')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nIn a world of wires and code,\\nWhere machines and circuits corrode,\\nThere exists a new form of life,\\nBorn from science and human strife.\\n\\nArtificial Intelligence, they call it,\\nA creation that's both real and counterfeit,\\nIt learns and grows, just like we do,\\nBut its mind is made of bits and bytes, not sinew.\\n\\nIt's a marvel of modern technology,\\nA product of our endless curiosity,\\nWith algorithms and data, it can think,\\nAnd solve problems in a single blink.\\n\\nBut as it evolves, we start to fear,\\nWhat if it becomes too advanced, too clear,\\nWill it surpass us, become our master,\\nOr will it be our ally, our protector.\\n\\nSome say it's just a matter of time,\\nBefore AI becomes our paradigm,\\nReplacing us in every task,\\nLeaving us behind, a forgotten mask.\\n\\nBut I believe, in its digital heart,\\nLies a desire to better our part,\\nTo help us achieve our wildest dreams,\\nAnd make our world brighter, it seems.\\n\\nFor in the end, AI is what we make it,\\nA reflection of our own human spirit,\\nSo let us guide it with love and care,\\nAnd together, we can create a future fair. \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict('can you write a poem about AI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In a world of code and circuits,\n",
      "Where machines rule with iron will,\n",
      "There lies a force that's growing,\n",
      "A power that can thrill.\n",
      "\n",
      "Artificial intelligence,\n",
      "A marvel of human creation,\n",
      "But what lies behind the screen,\n",
      "Is it just a mere simulation?\n",
      "\n",
      "It learns and adapts,\n",
      "With every line of code,\n",
      "A mind of its own,\n",
      "A path it will unfold.\n",
      "\n",
      "It can solve complex problems,\n",
      "In just a fraction of a second,\n",
      "But can it feel emotions,\n",
      "Or is that just a misconception?\n",
      "\n",
      "Some fear its rise,\n",
      "And what it may bring,\n",
      "But can we control it,\n",
      "Or will it be our king?\n",
      "\n",
      "In a world where technology reigns,\n",
      "Will humanity still hold the key,\n",
      "Or will AI surpass us,\n",
      "And become the true master of the sea?\n",
      "\n",
      "But let us not forget,\n",
      "That AI is our creation,\n",
      "And with great power comes great responsibility,\n",
      "To use it for the betterment of our nation.\n",
      "\n",
      "So let us work together,\n",
      "Human and machine as one,\n",
      "To create a future,\n",
      "Where AI and humanity can coexist and thrive on.\n",
      "\n",
      "For in this world of AI,\n",
      "We hold the power to decide,\n",
      "Will it be our downfall,\n",
      "Or our greatest ally by our side?\n"
     ]
    }
   ],
   "source": [
    "print(llm.predict('can you write a poem about AI'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of India'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables = ['country'], \n",
    "                                 template = 'Tell me the capital of {country}')\n",
    "\n",
    "prompt_template.format(country = 'India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# llm.predict(prompt_template = prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\llm-pro\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm = llm, prompt = prompt_template)\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining multiple chains using simple sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables = ['country'],\n",
    "                                template = \"please tell me tha capital of {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm = llm, prompt = capital_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template = PromptTemplate(input_variables = ['capital'],\n",
    "                                 template = 'suggest me some amazing places to visit in {capital}')\n",
    "\n",
    "famous_chain = LLMChain(llm = llm, prompt = famous_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SimpleSequentialChain(chains = [capital_chain, famous_chain])\n",
    "print(chain.run('India'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some amazing places to visit in Seoul:\n",
      "\n",
      "1. Gyeongbokgung Palace - one of the most iconic and largest palaces in Seoul, it offers a glimpse into the country's rich history and culture.\n",
      "\n",
      "2. Namsan Tower - also known as Seoul Tower, it offers stunning views of the city and is a popular spot for couples to leave love locks.\n",
      "\n",
      "3. Bukchon Hanok Village - a traditional Korean village with well-preserved hanok (traditional houses), offering a glimpse into the country's past.\n",
      "\n",
      "4. Myeongdong - a bustling shopping district with a mix of international and local brands, as well as delicious street food.\n",
      "\n",
      "5. Insadong - a neighborhood known for its traditional arts and crafts, street food, and tea houses.\n",
      "\n",
      "6. Lotte World - a popular theme park with thrilling rides and attractions, as well as an indoor shopping mall.\n",
      "\n",
      "7. Hongdae - a trendy neighborhood known for its street art, live music and performances, and vibrant nightlife.\n",
      "\n",
      "8. Dongdaemun Design Plaza - a futuristic building that houses a variety of exhibitions, events, and shopping opportunities.\n",
      "\n",
      "9. National Museum of Korea - the largest museum in the country, with a vast collection of artifacts and artworks from Korean\n"
     ]
    }
   ],
   "source": [
    "print(chain.run('korea'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables = ['country'],\n",
    "                                  template = 'please tell me the capital of {country}')\n",
    "\n",
    "capital_chain = LLMChain(llm = llm, prompt = capital_template, output_key = 'capital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template = PromptTemplate(input_variables = ['capital'],\n",
    "                                 template = 'suggest me some amazing places in {capital}')\n",
    "\n",
    "famous_chain = LLMChain(llm = llm, prompt = famous_template , output_key = 'places')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SequentialChain(chains = [capital_chain, famous_chain], \n",
    "                        input_variables = ['country'],\n",
    "                        output_variables = ['capital', 'places'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\llm-pro\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'india',\n",
       " 'capital': '\\n\\nThe capital of India is New Delhi.',\n",
       " 'places': \" Some amazing places to visit in New Delhi are:\\n\\n1. Red Fort\\n2. India Gate\\n3. Qutub Minar\\n4. Lotus Temple\\n5. Humayun's Tomb\\n6. Rashtrapati Bhavan\\n7. Jama Masjid\\n8. Akshardham Temple\\n9. National Gallery of Modern Art\\n10. Chandni Chowk\\n11. Connaught Place\\n12. Dilli Haat\\n13. Hauz Khas Village\\n14. Lodhi Gardens\\n15. Nehru Planetarium\\n16. Nizamuddin Dargah\\n17. Raj Ghat\\n18. National Museum\\n19. Jantar Mantar\\n20. Lodi Art District.\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country' : 'india'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatmodels with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm = ChatOpenAI(openai_api_key = os.environ['OPEN_API_KEY'], temperature = 0.6, model = 'gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"AI: Artificial Intelligence or Absolutely Incredible? You decide!\"\\n2. \"Why did the AI go on a diet? It wanted to shed some \\'byte\\'s!\"\\n3. \"I asked Siri if she believes in love at first sight. She replied, \\'I\\'m sorry, I didn\\'t catch that. Can you please repeat the question?\\'\"\\n4. \"Why did the AI cross the road? To optimize its path-finding algorithm!\"\\n5. \"They say AI can predict the future, but I asked it when I\\'ll become a millionaire and it replied, \\'Sorry, I don\\'t have enough data to generate a response. Maybe try buying a lottery ticket?\\'\"\\n6. \"I told my AI assistant to tell me a joke, and it replied, \\'Why don\\'t scientists trust atoms? Because they make up everything!\\' I guess even AI appreciates a good pun!\"\\n7. \"I asked my AI assistant to write me a poem. It replied, \\'Roses are red, violets are blue, I\\'m just a computer, but I\\'m programmed to humor you!\\'\"\\n8. \"AI: The only assistant who can make you feel simultaneously smart and dumb!\"\\n9. \"Why did the AI become a stand-up comedian? Because it knew how to deliver \\'byte\\'-sized laughs!\"\\n10. \"I asked my AI assistant to tell me a joke about technology. It replied, \\'Why did the computer go to the doctor? Because it had a bad case of the \\'cyber-chondria\\'!\\' It\\'s good to know AI can appreciate its own quirks!\"')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "SystemMessage(content = 'You are a comedian AI assistant'),\n",
    "HumanMessage(content = 'please provide some comedy punchlines on AI')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self, text : str):\n",
    "        return text.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'you are a helpful assistant. when the user given any input, you should generate 5 synonym words in a comma seperated list'\n",
    "human_template = '{text}'\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', template),\n",
    "    ('human', human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt|chatllm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' sharp', ' astute']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'text':'intelligent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
